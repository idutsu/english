from transformers import AutoModelForCausalLM, AutoTokenizer
import torch, requests, json, re, time

API_BASE_URL = "https://idutsu.com"

def validate_output(text: str):
    try:
        data = json.loads(text)
        if not isinstance(data, list) or len(data) == 0:
            print("ç©ºã®é…åˆ—ã¾ãŸã¯é…åˆ—ã§ã¯ã‚ã‚Šã¾ã›ã‚“")
            return {"data": text, "error": "ç©ºã®é…åˆ—ã¾ãŸã¯é…åˆ—ã§ã¯ã‚ã‚Šã¾ã›ã‚“"}
        for i, item in enumerate(data, start=1):
            if not isinstance(item, dict):
                return {"data": text, "error": f"{i} ç•ªç›®ã®è¦ç´ ã¯è¾æ›¸å‹ã§ã¯ã‚ã‚Šã¾ã›ã‚“: {item}"}
            if "en" not in item or "ja" not in item:
                return {"data": text, "error": f"{i} ç•ªç›®ã®è¦ç´ ã« 'en' ã¾ãŸã¯ 'ja' ãŒã‚ã‚Šã¾ã›ã‚“: {item}"}
            if re.search(r"[ã-ã‚“ã‚¡-ãƒ³ä¸€-é¾¥ã€…]", item["en"]):
                return {"data": text, "error": f"{i} ç•ªç›®ã®è¦ç´ ã® 'en' ã«æ—¥æœ¬èªãŒå«ã¾ã‚Œã¦ã„ã¾ã™: {item['en']}"}
            if re.search(r"[a-zA-Z]", item["ja"]):
                return {"data": text, "error": f"{i} ç•ªç›®ã®è¦ç´ ã® 'ja' ã«ã‚¢ãƒ«ãƒ•ã‚¡ãƒ™ãƒƒãƒˆãŒå«ã¾ã‚Œã¦ã„ã¾ã™: {item['ja']}"}
            if re.search(r"[{}\[\]<>]", item["ja"]):
                return {"data": text, "error": f"{i} ç•ªç›®ã®è¦ç´ ã® 'ja' ã«ä¸æ­£ãªè¨˜å·ãŒå«ã¾ã‚Œã¦ã„ã¾ã™: {item['ja']}"}
            if re.search(r"[{}\[\]<>]", item["en"]):
                return {"data": text, "error": f"{i} ç•ªç›®ã®è¦ç´ ã® 'en' ã«ä¸æ­£ãªè¨˜å·ãŒå«ã¾ã‚Œã¦ã„ã¾ã™: {item['en']}"}
        return {"data": data, "error": None}
    except json.JSONDecodeError as e:
        return {"data": text, "error": f"JSONDecodeError: {e.msg} at pos {e.pos}"}

# ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿
MODEL_PATH = "/models/Llama-3-ELYZA-JP-8B"
print("ãƒ¢ãƒ‡ãƒ«ï¼ˆLlama-3-ELYZA-JP-8Bï¼‰ã‚’èª­ã¿è¾¼ã‚“ã§ã„ã¾ã™...")
tok = AutoTokenizer.from_pretrained(MODEL_PATH)
if tok.pad_token_id is None and tok.eos_token_id is not None:
    tok.pad_token = tok.eos_token
model = AutoModelForCausalLM.from_pretrained(
    MODEL_PATH,
    device_map="auto",
    torch_dtype=torch.float16
).eval()

sys = (
    "ã‚ãªãŸã¯è‹±èªå­¦ç¿’ã®ãŸã‚ã®è‹±èªä¾‹æ–‡ã‚¸ã‚§ãƒãƒ¬ãƒ¼ã‚¿ãƒ¼ã§ã™ã€‚"
    "ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã§æŒ‡å®šã•ã‚ŒãŸãƒ•ãƒ¬ãƒ¼ã‚ºã‚’ä½¿ã£ã¦è‹±èªä¾‹æ–‡ã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚"
    "ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã§æŒ‡å®šã•ã‚ŒãŸå€‹æ•°ã ã‘è‹±èªä¾‹æ–‡ã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚"
    "è‹±èªä¾‹æ–‡ã®ä¸»èªã¯ã€æŒ‡å®šãŒãªã‘ã‚Œã°å¿…ãšã€ŒIï¼ˆç§ï¼‰ã€ã«ã—ã¦ãã ã•ã„ã€‚"
    "å‡ºåŠ›ã¯å¿…ãšæœ‰åŠ¹ãªJSONé…åˆ— ([]) ã«ã—ã¦ãã ã•ã„ã€‚"
    'JSONé…åˆ—å†…ã®å„è¦ç´ ã¯å¿…ãš{"en": "...", "ja": "..."}ã®è¾æ›¸å‹ã«ã—ã¦ãã ã•ã„ã€‚'
    'å‡ºåŠ›ä¾‹ï¼š[{"en": "I go to school.", "ja": "ç§ã¯å­¦æ ¡ã«è¡Œãã¾ã™ã€‚"},{"en": "I play soccer.", "ja": "ç§ã¯ã‚µãƒƒã‚«ãƒ¼ã‚’ã—ã¾ã™ã€‚"},{"en": "I eat breakfast.", "ja": "ç§ã¯æœé£Ÿã‚’é£Ÿã¹ã¾ã™ã€‚"}]'
    'å‡ºåŠ›ã¯JSONé…åˆ—ã¨ã—ã¦æœ‰åŠ¹ã«ãªã‚‹ã‚ˆã†å¿…ãš"["ã§å§‹ã¾ã‚Š"]"ã§çµ‚ã‚ã‚‹ã‚ˆã†ã«ã—ã¦ãã ã•ã„ã€‚'
    "å’Œè¨³ã¯å¿…ãšæŒ‡å®šã•ã‚ŒãŸæ–‡è¨€ã‚’ãã®ã¾ã¾ä½¿ã£ã¦ãã ã•ã„ã€‚"
    "å‡ºåŠ›ã™ã‚‹è‹±èªä¾‹æ–‡ã¯çŸ­ãã‚·ãƒ³ãƒ—ãƒ«ã«ã—ã¦ãã ã•ã„ã€‚"
    "å‹•è©ã¯ä¸€æ–‡ã«ä»˜ãä¸€å›ã«ã—ã¦ãã ã•ã„ã€‚"
    "æ–‡ã®é€”ä¸­ã§æ¥ç¶šè©ã‚„å¥èª­ç‚¹ã‚’ä½¿ã‚ãªã„ã§ãã ã•ã„ã€‚"
    "å‰ç½®ãã‚„ãƒ¡ã‚¿ç™ºè¨€ã¯ç¦æ­¢ã§ã™ã€‚å›ç­”ã®ã¿å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚"
)

# DBã‹ã‚‰ãƒ•ãƒ¬ãƒ¼ã‚ºã‚’å–å¾—
r = requests.get(f"{API_BASE_URL}/fetch/phrases", timeout=60)
r.raise_for_status()
phrases = r.json()["rows"]

done = 0

for phrase in phrases:
    en = phrase["en"]
    ja = phrase["ja"]
    phrase_id = phrase["id"]

    user_prompt = f"ãƒ•ãƒ¬ãƒ¼ã‚ºï¼š{en}ï¼ˆ{ja}ï¼‰ã€‚ å€‹æ•°ï¼š3ã€‚"
    messages = [
        {"role": "system", "content": sys},
        {"role": "user", "content": user_prompt}
    ]

    prompt_str = tok.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)
    inputs = tok(prompt_str, return_tensors="pt").to("cuda")

    count = 3
    print(f"ã€Œ{en}ï¼ˆ{ja}ï¼‰ã€ã§è‹±èªä¾‹æ–‡ã‚’{count}æ–‡ç”Ÿæˆã—ã¾ã™ã€‚")

    with torch.no_grad():
        output_ids = model.generate(
            **inputs,
            max_new_tokens=512,
            do_sample=True,
            temperature=0.8,
            top_p=0.95,
            pad_token_id=tok.pad_token_id or tok.eos_token_id
        )

    input_len = inputs["input_ids"].shape[1]
    generated_ids = output_ids[0][input_len:]
    text = tok.decode(generated_ids, skip_special_tokens=True)

    result = validate_output(text)

    if result["error"] is None:
        # æˆåŠŸãƒ­ã‚°
        print(f"ğŸ“ æ­£ã—ã„JSONã®å‡ºåŠ›ã«æˆåŠŸã—ã¾ã—ãŸ")
        out = {"text": text, "phrase": phrase_id, "score": "good"}
        try:
            resp = requests.post(f"{API_BASE_URL}/insert/outputs", json=out, timeout=30)
            resp.raise_for_status()
            print(f"ğŸ“ æ­£ã—ã„JSONå‡ºåŠ›ã®ä¿å­˜ã«æˆåŠŸã—ã¾ã—ãŸ (phrase_id={phrase_id}):", resp.json())
        except requests.RequestException as e:
            print(f"âš ï¸ æ­£ã—ã„JSONå‡ºåŠ›ã®ä¿å­˜ã«å¤±æ•—ã—ã¾ã—ãŸ (phrase_id={phrase_id}):", e)
        # ä¾‹æ–‡ã‚’DBï¼ˆsentsï¼‰ã«ä¿å­˜
        payload = [{"en": ex["en"], "ja": ex["ja"], "phrase": phrase_id} for ex in result["data"]]
        try:
            resp = requests.post(f"{API_BASE_URL}/insert/sents", json=payload, timeout=30)
            resp.raise_for_status()
            print(f"âœ… ä¾‹æ–‡ã®ä¿å­˜ã«æˆåŠŸã—ã¾ã—ãŸ (phrase_id={phrase_id}):", resp.json())
            conmplete += 1
        except requests.RequestException as e:
            print(f"âš ï¸ ä¾‹æ–‡ã®ä¿å­˜ã«å¤±æ•—ã—ã¾ã—ãŸ (phrase_id={phrase_id}):", e)
    else:
        # å¤±æ•—ãƒ­ã‚°
        print(f"ğŸ“ æ­£ã—ã„JSONã®å‡ºåŠ›ã«å¤±æ•—ã—ã¾ã—ãŸ: result['error']")
        out = {"text": text, "phrase": phrase_id, "score": "bad", "comment": result["error"]}
        try:
            resp = requests.post(f"{API_BASE_URL}/insert/outputs", json=out, timeout=30)
            resp.raise_for_status()
            print(f"ğŸ“ èª¤ã£ãŸJSONå‡ºåŠ›ã®ä¿å­˜ã«æˆåŠŸã—ã¾ã—ãŸ (phrase_id={phrase_id}):", resp.json())
        except requests.RequestException as e:
            print(f"âš ï¸ èª¤ã£ãŸJSONå‡ºåŠ›ã®ä¿å­˜ã«å¤±æ•—ã—ã¾ã—ãŸ (phrase_id={phrase_id}):", e)

    # é€£æŠ•ã—ã™ããªã„ã‚ˆã†ã«ï¼ˆä»»æ„ï¼‰
    time.sleep(0.3)


print(f"ä¾‹æ–‡ç”Ÿæˆæ•°:{done} ä»¶")